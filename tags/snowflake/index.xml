<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Snowflake - Tag - t-lark.github.io</title>
        <link>https://t-lark.github.io/tags/snowflake/</link>
        <description>Snowflake - Tag - t-lark.github.io</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 03 Apr 2025 12:18:44 -0700</lastBuildDate><atom:link href="https://t-lark.github.io/tags/snowflake/" rel="self" type="application/rss+xml" /><item>
    <title>Managing Licensed Software with Data</title>
    <link>https://t-lark.github.io/posts/managing_licensed_software/</link>
    <pubDate>Thu, 03 Apr 2025 12:18:44 -0700</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/managing_licensed_software/</guid>
    <description><![CDATA[<h2 id="turn-an-it-cost-center-into-an-it-cost-savings-center">Turn an IT Cost Center into an IT Cost Savings Center!</h2>
<p>So many times in my career I have heard IT/Ops teams be referred to as overhead. I have also heard IT being described as
&ldquo;just keeping the lights on,&rdquo; and all the adjacent things one can say similar to this. These type of statements has always
made me want to prove that IT isn&rsquo;t really just those type of things. I have always been trying to implement some sort of
cost savings where we can definitively decide where to cut costs. You never want to cut costs around things that have
a high positive impact. Since in many ways you do get what you pay for at times, and what you pay for may be very worth
it. So, IT is a cost savings center, a service provider, an enabler, an enhancer and much more than some of the
stereotypical things you might hear about how people perceive IT.</p>]]></description>
</item>
<item>
    <title>Building Endpoint Performance Metrics</title>
    <link>https://t-lark.github.io/posts/building_endpoint_performance_metrics/</link>
    <pubDate>Tue, 14 Jan 2025 15:35:46 -0800</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/building_endpoint_performance_metrics/</guid>
    <description><![CDATA[<p>Many organizations today still struggle with hardware refresh, right sizing hardware specs, and understanding the performance
impact of tools and software across their fleet of end user devices. This has been a problem since the beginning of humans
incorporating technology into their professional lives. In my 25+ year career I don&rsquo;t think I have ever had a job where
these problems were considered solved, and I don&rsquo;t think we ever got close to solving them. A major factor we have all faced
while trying to solve this problem is the lack of data compounded by the problem of being able to use and leverage the data
in a meaningful way.</p>]]></description>
</item>
<item>
    <title>Leveraging Application Usage Data From Munki</title>
    <link>https://t-lark.github.io/posts/app-usage-data-munki-fleet-snowflake/</link>
    <pubDate>Tue, 26 Mar 2024 18:43:26 -0700</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/app-usage-data-munki-fleet-snowflake/</guid>
    <description><![CDATA[<a class="lightgallery" href="/img/fleet_munki_snowflake.png" title="/img/fleet_munki_snowflake.png" data-thumbnail="/img/fleet_munki_snowflake.png">
        
    </a>
<h3 id="getting-application-usage-data-at-scale-with-munki">Getting Application Usage Data at Scale With Munki</h3>
<p><a href="https://github.com/munki/munki" target="_blank" rel="noopener noreffer ">Munki</a> is a series of tools and a popular application state management tool many Mac Admins across the globe
use. Some out-of-box features of Munki solve problems many commercial MDMs still cannot solve to this day. It allows
a Mac Admin to write some declarative data and have Munki takes care of the rest for you. We use it to manage
and patch all of our third party apps in conjunction with <a href="https://github.com/autopkg/autopkg" target="_blank" rel="noopener noreffer ">AutoPKG</a>.</p>]]></description>
</item>
<item>
    <title>More Osquery Data Modeling in Snowflake</title>
    <link>https://t-lark.github.io/posts/more-osquery-data-modeling-snowflake/</link>
    <pubDate>Thu, 25 Jan 2024 20:24:28 -0800</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/more-osquery-data-modeling-snowflake/</guid>
    <description><![CDATA[<h1 id="data-modeling-osquery-data-in-snowflake">Data Modeling osquery Data in Snowflake</h1>
<p>We have been working on many projects the past few months, and osquery data pipelines with the help of <a href="https://fleetdm.com/" target="_blank" rel="noopener noreffer ">FleetDM</a>
has been one of our constant works in progress. Before I dive into the data modeling part, I wanted to share how we scaled
this data out. We ended up going forward with FleetDM&rsquo;s SaaS offering over self-hosting the app. However, we are still
streaming query results from FleetDM cloud to Snowflake over <a href="https://aws.amazon.com/kinesis/data-firehose/" target="_blank" rel="noopener noreffer ">AWS Kinesis Firehose</a> and
we now have data streaming from FleetDM into Snowflake at a very fast rate and high volume. We are typically collecting
data from osquery every hour on most things, and we have a lesser number of queries that run every 12 hours or once a
day.</p>]]></description>
</item>
<item>
    <title>Working with osquery Data in Snowflake</title>
    <link>https://t-lark.github.io/posts/osquery-data-in-snowflake/</link>
    <pubDate>Thu, 31 Aug 2023 18:01:31 -0700</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/osquery-data-in-snowflake/</guid>
    <description><![CDATA[<p>I recently told my dog, Booms, all about how you can use osquery data in Snowflake. Needless to say, he was quite impressed
with all the use cases and in-depth data you can model about your fleet of laptops using osquery data in Snowflake.</p>
<a class="lightgallery" href="/img/booms-snow1.jpg" title="/img/booms-snow1.jpg" data-thumbnail="/img/booms-snow1.jpg">
        
    </a>
<blockquote>
<p>Booms came to the office with me, and he even got a bit of company swag! As we spent the day working I told him
all about all the work my team was doing with osquery. Anyone can see in this pic of him, he is very impressed
with the speed and scale one can leverage data from osquery in Snowflake</p>]]></description>
</item>
<item>
    <title>Snowflake Osquery Fleet Magic</title>
    <link>https://t-lark.github.io/posts/snowflake-osquery-fleet-magic/</link>
    <pubDate>Thu, 13 Jan 2022 17:07:04 -0800</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/snowflake-osquery-fleet-magic/</guid>
    <description><![CDATA[<h1 id="snowflake-osquery-and-fleet-is-pure-magic">Snowflake, osquery and Fleet is Pure Magic!</h1>
<p>Many of you have probably heard of <a href="https://osquery.io/" target="_blank" rel="noopener noreffer ">osquery</a>, which is software you can install onto a computer that
allows humans to query the OS to return fast and reliable system data. Osquery is not new, and many Organizations have been
using it in various capacity for years now. Vendors and developers also ship osquery with their products these days as well.
This allows a developer or vendor to collect local data fast and reliably for their software and solutions.</p>]]></description>
</item>
<item>
    <title>IT &amp; Ops Data with Snowflake Part III</title>
    <link>https://t-lark.github.io/posts/ops-data-snowflake-pt3/</link>
    <pubDate>Tue, 10 Aug 2021 20:02:00 -0700</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/ops-data-snowflake-pt3/</guid>
    <description><![CDATA[<h1 id="gain-oversight-of-your-asset-inventory-with-snowflake">Gain Oversight of your Asset Inventory with Snowflake</h1>
<p>Welcome to Part III of my mini blog series on being data driven with Snowflake. This post will be solely dedicated to
how an organization can leverage a platform like Snowflake to improve their asset and inventory controls. Both <a href="https://t-lark.github.io/posts/ops-data-snowflake/" target="_blank" rel="noopener noreffer ">Part I</a>
and <a href="https://t-lark.github.io/posts/ops-data-snowflake-pt2/" target="_blank" rel="noopener noreffer ">Part II</a> can be viewed with those links if you haven&rsquo;t read
them yet. This post will focus on end user devices for the most part and not networking hardware, application catalogs,
servers, and so forth.  The concepts in this post could be applied to those things though.</p>]]></description>
</item>
<item>
    <title>IT &amp; Ops Data with Snowflake Part II</title>
    <link>https://t-lark.github.io/posts/ops-data-snowflake-pt2/</link>
    <pubDate>Thu, 22 Apr 2021 20:02:00 -0700</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/ops-data-snowflake-pt2/</guid>
    <description><![CDATA[<h1 id="working-with-data-in-snowflake">Working with Data in Snowflake</h1>
<p>Welcome to Part II of my miniseries blog around Snowflake with IT &amp; Ops Data. If you have not read <a href="https://t-lark.github.io/posts/ops-data-snowflake/" target="_blank" rel="noopener noreffer ">Part I</a>,
you may click that link to read it first. Data has always been very important, and Snowflake just makes using the data a ton
easier than we have ever had before. This post will focus on some basic ways one can work with data with in Snowflake.
For this blog I will be focusing on JSON data stored in Snowflake columns. <a href="https://en.wikipedia.org/wiki/JSON" target="_blank" rel="noopener noreffer ">JSON</a> documents are very common all over tech. Especially in things
like <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener noreffer ">REST APIs</a>, so if you haven&rsquo;t worked with JSON
you will work with JSON data most likely at some point.</p>]]></description>
</item>
<item>
    <title>IT &amp; Ops Data with Snowflake Part I</title>
    <link>https://t-lark.github.io/posts/ops-data-snowflake/</link>
    <pubDate>Thu, 15 Apr 2021 20:00:08 -0700</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/ops-data-snowflake/</guid>
    <description><![CDATA[<h1 id="be-data-driven-in-itops-with-snowflake">Be Data Driven in IT/Ops with Snowflake</h1>
<p>Technology changes very fast, and it keeps getting bigger and more complex.  We have so many systems these days, our
systems have systems.  It doesn&rsquo;t have to be complex and daunting to get reliable, and up-to-date data. Getting accurate
data, while getting it fast, is key to developing data driven strategies.  We no longer have to live in the constraints of
capacity, limited storage, and limited scalability. With the power and scale of the cloud, you can now simply just ship all of
your IT/Ops data to a centralized location and share it among your teams.</p>]]></description>
</item>
<item>
    <title>Shipping Jamf Webhooks with Fivetran</title>
    <link>https://t-lark.github.io/posts/shipping-jamf-webhooks/</link>
    <pubDate>Sat, 19 Sep 2020 21:27:27 -0700</pubDate>
    <author>tlark</author>
    <guid>https://t-lark.github.io/posts/shipping-jamf-webhooks/</guid>
    <description><![CDATA[<h1 id="shipping-jamf-pro-webhooks-to-snowflake">Shipping Jamf Pro Webhooks to Snowflake</h1>
<p>Jamf Pro has a builtin feature where you have the ability to ship a webhook event when specific events happen in their
application.  This allows for a near real time feed of event based data which you can consume and leverage to gain insights
about your fleet.  Jamf provides some documentation online, found <a href="https://www.jamf.com/developers/webhooks/" target="_blank" rel="noopener noreffer ">here</a>.</p>
<p>Webhooks are generated automatically, and near instantly when an event occurs.  In the linked documentation above you
will see all the possible webhooks and sample data of what each webhook ships.  There are many ways to ship webhooks,
and you can choose from many paths to take.  You can roll your own webhook receiver, you can ship webhooks directly to
cloud storage (S3, Azure Blob, GCP Cloud Storage), use one of many data ingestion tools, and so forth.  Right now we are
leveraging a tool called <a href="https://fivetran.com/" target="_blank" rel="noopener noreffer ">Fivetran</a>.  Fivetran has built in integration to many SaaS and cloud
services.  What tools work best for your Organization will be up to your Org to decide.</p>]]></description>
</item>
</channel>
</rss>
